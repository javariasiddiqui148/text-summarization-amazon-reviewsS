# -*- coding: utf-8 -*-
"""Textsummarization.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bIYbCCk5piWtIntrjpIEVdqoo1nhjcEM

# **PROJECT :"AMAZON FINE REVIEWS"**

***üîπ 6Ô∏è‚É£ requirements.txt***
"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile requirements.txt
# streamlit
# torch
# transformers
# sentencepiece
# pandas
# numpy
# sumy
# rouge
# scikit-learn
# matplotlib
# seaborn
# pyngrok

pip install -r requirements.txt

import kagglehub

# Download latest version
path = kagglehub.dataset_download("bornaetminan/amazon-fine-reviews-cleaned-ml-ready")

print("Path to dataset files:", path)

import torch
from transformers import T5Tokenizer, T5ForConditionalGeneration

#!ls -R {path}

import os

df = pd.read_csv(os.path.join(path, "amazon_reviews_full_clean.csv"))
df.head()

"""***üîπ 1Ô∏è‚É£ DATA LOADING & PREPROCESSING***"""

import pandas as pd
import re
from sklearn.model_selection import train_test_split
import os

# Load data
df = pd.read_csv(os.path.join(path, "amazon_reviews_full_clean.csv"))

# Keep required columns
df = df[['clean_text', 'clean_summary']].dropna()

# Rename for consistency
df.rename(columns={'clean_text': 'text', 'clean_summary': 'summary'}, inplace=True)

# Clean text
def clean_text(text):
    text = text.lower()
    text = re.sub(r'[^a-zA-Z ]', '', text)
    return text

df['text'] = df['text'].apply(clean_text)
df['summary'] = df['summary'].apply(clean_text)

# Limit text length (important for transformers)
df = df[df['text'].str.split().str.len() < 400]

# Train-test split
train_df, test_df = train_test_split(
    df, test_size=0.2, random_state=42
)

# Save
train_df.to_csv("train.csv", index=False)
test_df.to_csv("test.csv", index=False)

print("Train size:", train_df.shape)
print("Test size:", test_df.shape)

display(train_df.head())

"""***üîπ 2Ô∏è‚É£ DATA VISUALIZATION (EDA)***"""

import pandas as pd
import matplotlib.pyplot as plt

df = pd.read_csv("train.csv")

df['text_len'] = df['text'].apply(lambda x: len(x.split()))
df['summary_len'] = df['summary'].apply(lambda x: len(x.split()))

plt.hist(df['text_len'], bins=50)
plt.title("Review Length Distribution")
plt.xlabel("Words")
plt.ylabel("Frequency")
plt.show()

plt.hist(df['summary_len'], bins=30)
plt.title("Summary Length Distribution")
plt.xlabel("Words")
plt.ylabel("Frequency")
plt.show()

"""***üîπ 3Ô∏è‚É£ MODEL TRAINING (TEXT SUMMARIZATION)***

# üî∏ 3A. TextRank (Baseline)
"""

from sumy.parsers.plaintext import PlaintextParser
from sumy.nlp.tokenizers import Tokenizer
from sumy.summarizers.text_rank import TextRankSummarizer

def textrank_summary(text, sentences=2):
    parser = PlaintextParser.from_string(text, Tokenizer("english"))
    summarizer = TextRankSummarizer()
    summary = summarizer(parser.document, sentences)
    return " ".join(str(s) for s in summary)

"""# üî∏ 3B. T5-Small Model"""

from transformers import T5Tokenizer, T5ForConditionalGeneration
import torch

device = "cpu"

tokenizer = T5Tokenizer.from_pretrained("t5-small")
model = T5ForConditionalGeneration.from_pretrained("t5-small").to(device)

def t5_summary(text):
    if not isinstance(text, str):
        return ""

    input_text = "summarize: " + text[:1000]

    input_ids = tokenizer.encode(
        input_text,
        return_tensors="pt",
        max_length=512,
        truncation=True
    ).to(device)

    output = model.generate(
        input_ids,
        max_length=40,
        num_beams=4,
        early_stopping=True
    )

    return tokenizer.decode(output[0], skip_special_tokens=True)

import nltk
nltk.download('punkt_tab')

"""***üîπ 4Ô∏è‚É£ MODEL EVALUATION (ROUGE)***"""

import pandas as pd
from rouge import Rouge

test_df = pd.read_csv("test.csv")
rouge = Rouge()

def evaluate(model_func, n=30):
    scores = []
    for i in range(n):
        pred = model_func(test_df.iloc[i]['text'])
        ref = test_df.iloc[i]['summary']
        score = rouge.get_scores(pred, ref)[0]['rouge-l']['f']
        scores.append(score)
    return sum(scores) / len(scores)

print("TextRank ROUGE-L:", evaluate(textrank_summary))
print("T5 ROUGE-L:", evaluate(t5_summary))

"""***üîπ 5Ô∏è‚É£ STREAMLIT APPLICATION ***"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# from transformers import T5Tokenizer, T5ForConditionalGeneration
# from sumy.parsers.plaintext import PlaintextParser
# from sumy.nlp.tokenizers import Tokenizer
# from sumy.summarizers.text_rank import TextRankSummarizer
# 
# # ===============================
# # Page Config
# # ===============================
# st.set_page_config(
#     page_title="Amazon Review Summarizer",
#     page_icon="üõí",
#     layout="centered"
# )
# 
# # ===============================
# # CSS Styling (FIXED)
# # ===============================
# st.markdown(
#     """
#     <style>
#     .stApp {
#         background: linear-gradient(to right, #f5f7fa, #c3cfe2);
#         font-family: 'Segoe UI', sans-serif;
#     }
# 
#     h1 {
#         text-align: center;
#         color: #0d47a1;
#     }
# 
#     .subtitle {
#         text-align: center;
#         color: #37474f;
#         margin-bottom: 25px;
#     }
# 
#     .summary-box {
#         background-color: #ffffff;
#         padding: 20px;
#         border-radius: 14px;
#         box-shadow: 0px 6px 15px rgba(0,0,0,0.12);
#         margin-top: 20px;
#         font-size: 16px;
#     }
# 
#     .footer {
#         text-align: center;
#         color: gray;
#         margin-top: 40px;
#         font-size: 14px;
#     }
# 
#     footer {
#         visibility: hidden;
#     }
#     </style>
#     """,
#     unsafe_allow_html=True
# )
# 
# # ===============================
# # Title
# # ===============================
# st.markdown("<h1>üõí Amazon Review Text Summarization ü§ñ</h1>", unsafe_allow_html=True)
# st.markdown(
#     "<div class='subtitle'>Summarize Amazon product reviews using NLP models</div>",
#     unsafe_allow_html=True
# )
# 
# # ===============================
# # Input
# # ===============================
# text = st.text_area(
#     "‚úçÔ∏è Enter Review Text",
#     height=180,
#     placeholder="Paste your Amazon product review here..."
# )
# 
# model_choice = st.selectbox(
#     "ü§ñ Choose Model",
#     ["TextRank", "T5"]
# )
# 
# # ===============================
# # Load T5
# # ===============================
# @st.cache_resource
# def load_t5():
#     tokenizer = T5Tokenizer.from_pretrained("t5-small")
#     model = T5ForConditionalGeneration.from_pretrained("t5-small")
#     return tokenizer, model
# 
# # ===============================
# # Generate Summary
# # ===============================
# if st.button("üöÄ Generate Summary"):
#     if text.strip() == "":
#         st.warning("‚ö†Ô∏è Please enter review text first.")
#     else:
#         with st.spinner("üß† Generating summary..."):
#             if model_choice == "TextRank":
#                 parser = PlaintextParser.from_string(text, Tokenizer("english"))
#                 summarizer = TextRankSummarizer()
#                 summary_sentences = summarizer(parser.document, 2)
#                 summary = " ".join(str(s) for s in summary_sentences)
#             else:
#                 tokenizer, model = load_t5()
#                 input_text = "summarize: " + text[:1000]
#                 input_ids = tokenizer.encode(
#                     input_text,
#                     return_tensors="pt",
#                     max_length=512,
#                     truncation=True
#                 )
#                 output = model.generate(input_ids, max_length=40)
#                 summary = tokenizer.decode(output[0], skip_special_tokens=True)
# 
#         st.markdown(
#             f"""
#             <div class="summary-box">
#                 <h4>üìå Summary</h4>
#                 {summary}
#             </div>
#             """,
#             unsafe_allow_html=True
#         )
# 
# # ===============================
# # Footer
# # ===============================
# st.markdown(
#     """
#     <div class="footer">
#         <hr>
#         Developed by <b>javaria Siddiqui</b> ‚ù§Ô∏è <br>
#         NLP Project | Streamlit ‚Ä¢ TextRank ‚Ä¢ T5 ü§ñ
#     </div>
#     """,
#     unsafe_allow_html=True
# )

!ngrok authtoken XXXXX

!ngrok

from pyngrok import ngrok

ngrok.set_auth_token("38INf7A7ntwgQ3FxKqVpwB7LF0X_2atGSEqxezbawN1xNii9f")

!streamlit run app.py &>/content/logs.txt &

public_url = ngrok.connect(addr='8501', proto='http')
print(f'Streamlit App URL: {public_url}')

"""# MADE BY JAVARIA
# [TO MISS TAYABA AKRAM]
"""